{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhjZxqzyz7DjJldiaFLo1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushi-2310/AI_Agent/blob/main/MarketResearch_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "52o8NwPB6t9d"
      },
      "outputs": [],
      "source": [
        "# !pip install -q fastapi nest-asyncio uvicorn pandas openai google-generativeai colabcode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "from fastapi import FastAPI, Form, UploadFile, File\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio, uvicorn\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "rDtRbjxvAAoa"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Config ---\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", userdata.get(\"GOOGLE_API_KEY\"))\n",
        "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
        "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}\"\n",
        "app = FastAPI()"
      ],
      "metadata": {
        "id": "dWzoyIhCACRe"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_graph = {\n",
        "    \"CTR\": {\"impacts\": [\"Conversions\"], \"influenced_by\": [\"Ad Text\", \"Targeting\"]},\n",
        "    \"CPC\": {\"impacts\": [\"ROI\"], \"influenced_by\": [\"Bidding Strategy\"]},\n",
        "}\n"
      ],
      "metadata": {
        "id": "dvVOSIihA_Ag"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_gemini(prompt):\n",
        "    payload = {\n",
        "        \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
        "        \"generationConfig\": {\n",
        "            \"maxOutputTokens\": 256,\n",
        "            \"temperature\": 0.7,\n",
        "            \"topP\": 0.9,\n",
        "            \"topK\": 40\n",
        "        }\n",
        "    }\n",
        "    resp = requests.post(GEMINI_URL, json=payload)\n",
        "    if resp.status_code != 200:\n",
        "        return f\"[ERROR] {resp.status_code}: {resp.text}\"\n",
        "    parts = resp.json().get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [])\n",
        "    return parts[0].get(\"text\", \"\") if parts else \"[No response]\"\n"
      ],
      "metadata": {
        "id": "ZLTumSiJAGkY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def get_home():\n",
        "    return \"\"\"\n",
        "    <html><head><title>Ad Copy Rewriter</title></head>\n",
        "    <body style=\"font-family:Arial; padding:20px;\">\n",
        "        <h2>üìù Rewrite Your Ad Copy</h2>\n",
        "        <form action=\"/generate\" method=\"post\">\n",
        "            <textarea name=\"content\" rows=\"6\" cols=\"70\" placeholder=\"Enter your original ad copy...\" required></textarea><br><br>\n",
        "            <label><strong>Select Tone:</strong></label>\n",
        "            <select name=\"tone\">\n",
        "                <option value=\"fun\">Fun</option>\n",
        "                <option value=\"professional\">Professional</option>\n",
        "                <option value=\"bold\">Bold</option>\n",
        "                <option value=\"conversational\">Conversational</option>\n",
        "                <option value=\"urgent\">Urgent</option>\n",
        "            </select><br><br>\n",
        "            <button type=\"submit\">Generate</button>\n",
        "        </form>\n",
        "        <hr>\n",
        "        <h3>üìÇ Upload CSV for Campaign Analysis</h3>\n",
        "        <form action=\"/upload\" enctype=\"multipart/form-data\" method=\"post\">\n",
        "            <input name=\"file\" type=\"file\" accept=\".csv\">\n",
        "            <button type=\"submit\">Upload & Analyze</button>\n",
        "        </form>\n",
        "    </body></html>\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "180V1eADAbLf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/generate\", response_class=HTMLResponse)\n",
        "async def generate_content(content: str = Form(...), tone: str = Form(...)):\n",
        "    prompt = f\"Rewrite the following ad copy in a {tone} tone, optimized for high engagement:\\n\\n{content}\"\n",
        "    generated_text = call_gemini(prompt)\n",
        "\n",
        "    # Evaluation\n",
        "    response_length = len(generated_text.split())\n",
        "    tone_keywords = {\n",
        "        \"fun\": [\"exciting\", \"wow\", \"fun\", \"awesome\", \"playful\", \"lol\", \"party\"],\n",
        "        \"professional\": [\"professional\", \"trusted\", \"experience\", \"solutions\", \"partner\"],\n",
        "        \"bold\": [\"guaranteed\", \"best ever\", \"never seen before\", \"unbeatable\"],\n",
        "        \"conversational\": [\"you\", \"let‚Äôs\", \"imagine\", \"we‚Äôve got\"],\n",
        "        \"urgent\": [\"now\", \"limited\", \"don‚Äôt wait\", \"only\", \"act fast\"]\n",
        "    }\n",
        "    matched_keywords = [kw for kw in tone_keywords.get(tone, []) if kw in generated_text.lower()]\n",
        "    tone_match_score = round(len(matched_keywords) / max(len(tone_keywords[tone]), 1), 2)\n",
        "    hallucination_flag = \"?\" if \"aliens\" in generated_text.lower() else \"No obvious hallucinations\"\n",
        "\n",
        "    html_output = f\"\"\"\n",
        "    <html><head><style>body{{font-family:Arial;padding:20px;}}</style></head>\n",
        "    <body>\n",
        "        <h2>üéØ Rewritten Ad Copy ({tone.title()} Tone)</h2>\n",
        "        <p><strong>Original:</strong> {content}</p><hr>\n",
        "        <pre>{generated_text}</pre>\n",
        "        <h3>üìä Evaluation Metrics</h3>\n",
        "        <ul>\n",
        "            <li><strong>Word Count:</strong> {response_length}</li>\n",
        "            <li><strong>Tone Match Score:</strong> {tone_match_score*100}%</li>\n",
        "            <li><strong>Hallucination Check:</strong> {hallucination_flag}</li>\n",
        "        </ul>\n",
        "        <h3>üîÅ Feedback</h3>\n",
        "        <form action=\"/feedback\" method=\"post\">\n",
        "            <input type=\"hidden\" name=\"prompt\" value=\"{content}\">\n",
        "            <input type=\"hidden\" name=\"output\" value=\"{generated_text}\">\n",
        "            <label>Was this helpful?</label>\n",
        "            <select name=\"feedback\">\n",
        "                <option value=\"positive\">üëç Yes</option>\n",
        "                <option value=\"negative\">üëé No</option>\n",
        "            </select>\n",
        "            <button type=\"submit\">Submit</button>\n",
        "        </form>\n",
        "        <br><a href=\"/\">üîô Back</a>\n",
        "    </body></html>\n",
        "    \"\"\"\n",
        "    return HTMLResponse(content=html_output)"
      ],
      "metadata": {
        "id": "kkQeVKvwAbzC"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/feedback\")\n",
        "async def feedback(prompt: str = Form(...), output: str = Form(...), feedback: str = Form(...)):\n",
        "    with open(\"feedback_log.csv\", \"a\") as f:\n",
        "        f.write(f'\"{prompt}\",\"{output}\",\"{feedback}\"\\n')\n",
        "    return HTMLResponse(\"<h2>‚úÖ Thank you for your feedback!</h2><a href='/'>üîô Back</a>\")\n"
      ],
      "metadata": {
        "id": "Kv33mmmeAkrQ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/upload\")\n",
        "async def upload_csv(file: UploadFile = File(...)):\n",
        "    df = pd.read_csv(file.file)\n",
        "    summary_prompt = f\"Here‚Äôs a CSV summary:\\n\\n{df.describe().to_string()}\\n\\n\"\n",
        "    step_1 = call_gemini(\"Summarize ad campaign performance:\\n\" + summary_prompt)\n",
        "    step_2 = call_gemini(\"Given the summary, what metrics are underperforming?\\n\" + step_1)\n",
        "    step_3 = call_gemini(\"Suggest improvements to boost the underperforming metrics:\\n\" + step_2)\n",
        "    step_4 = call_gemini(\"Generate a rewritten ad copy to reflect those suggestions:\\n\" + step_3)\n",
        "\n",
        "    return HTMLResponse(f\"\"\"\n",
        "        <html><body style=\"font-family:Arial; padding:20px;\">\n",
        "        <h2>üìà Agentic Analysis</h2>\n",
        "        <h3>Step 1: Summary</h3><pre>{step_1}</pre>\n",
        "        <h3>Step 2: Issues</h3><pre>{step_2}</pre>\n",
        "        <h3>Step 3: Improvements</h3><pre>{step_3}</pre>\n",
        "        <h3>Step 4: Rewritten Ad</h3><pre>{step_4}</pre>\n",
        "        <a href=\"/\">üîô Back</a></body></html>\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "IoAsGqlcApWZ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/evaluate\")\n",
        "async def evaluate_ad(output: str = Form(...), expected_keywords: str = Form(...)):\n",
        "    expected = expected_keywords.lower().split(\",\")\n",
        "    match_score = sum(1 for word in expected if word.strip() in output.lower()) / max(len(expected), 1)\n",
        "    return {\"keyword_match_score\": round(match_score, 2), \"output_length\": len(output.split())}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgtLV353Apd6",
        "outputId": "7645d29a-c5d7-4110-cc49-f13293794cbb"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-35' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-43' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_log = []\n",
        "@app.post(\"/log-feedback\")\n",
        "async def log_feedback(prompt: str = Form(...), output: str = Form(...), feedback: str = Form(...)):\n",
        "    memory_log.append({\"prompt\": prompt, \"output\": output, \"feedback\": feedback})\n",
        "    return {\"status\": \"logged\", \"log_size\": len(memory_log)}"
      ],
      "metadata": {
        "id": "gDs8KLloAx6W"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyngrok import ngrok\n",
        "# from google.colab import userdata\n",
        "# import os\n",
        "\n",
        "# # Set your ngrok authtoken from Colab secrets\n",
        "# NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "# if NGROK_AUTH_TOKEN:\n",
        "#     ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "#     print(\"ngrok authtoken set successfully.\")\n",
        "# else:\n",
        "#     print(\"NGROK_AUTH_TOKEN not found in Colab secrets. Please add it.\")"
      ],
      "metadata": {
        "id": "A2bjkTg7BI-S"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Enable Colab support\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Run FastAPI server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtyu-udAyGK",
        "outputId": "59583fab-5809-420c-eb60-c527c98a3270"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://1ef0-34-168-140-187.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [288]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-27T11:45:08+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2401:4900:883e:2e95:8996:960:4906:c515:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2401:4900:883e:2e95:8996:960:4906:c515:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2401:4900:883e:2e95:8996:960:4906:c515:0 - \"POST /generate HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [288]\n"
          ]
        }
      ]
    }
  ]
}